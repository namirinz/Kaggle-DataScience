# -*- coding: utf-8 -*-
"""Admission_Predict.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x2S2T69XlNqBqrUloOJEFUUNQ8Nj0lCp
"""

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/My Drive/Datasets/Admission_Predict

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.linear_model import LinearRegression,Lasso,Ridge
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error,mean_absolute_error
from sklearn.pipeline import make_pipeline
from sklearn.decomposition import PCA

df = pd.read_csv('datasets/Admission_Predict_Ver1.1.csv')

#display(df.head())

#display(df.info())

# display correlation of feature pair
#display(df.corr())

# We see that all feature except Serial No. have less correlation compare to Chance of Admit (label)
# So we drop it

# Feature selection
# # drop 'Serial No.' and 'Chance of Admit ' and change to numpy array
X = df.drop(columns = ['Serial No.','Chance of Admit '])
#display(X)

# Label selection
# # select 'Chance of Admit ' columns and change to numpy array
y = df['Chance of Admit ']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)

from sklearn.linear_model import LassoCV
from sklearn.linear_model import RidgeCV
scale = StandardScaler()
scale.fit(X_train)
X_train = scale.transform(X_train)
pca = PCA(n_components = 2)
pca.fit(X_train)
X_train = pca.transform(X_train)

X_test = scale.transform(X_test)
X_test = pca.transform(X_test)


la = LassoCV()
la.fit(X_train, y_train)
y_pred = la.predict(X_test)

print(la.alpha_)
print("Train score : ",la.score(X_train, y_train))
print("Test score : ",la.score(X_test, y_test))
print(mean_squared_error(y_test, y_pred))

Linereg = LinearRegression()
Ridreg = Ridge()
Lassreg = Lasso()

param_grid = {'alpha': [0.001, 0.01, 0.1, 1]}

Ridreg_cv = GridSearchCV(Ridreg, param_grid, n_jobs = -1)
Lassreg_cv = GridSearchCV(Lassreg, param_grid, n_jobs = -1)

Ridreg_cv.fit(X_train, y_train)
Lassreg_cv.fit(X_train, y_train)
Linereg.fit(X_train, y_train)

y_pred_rid = Ridreg_cv.predict(X_test)
y_pred_lass = Lassreg_cv.predict(X_test)
y_pred_line = Linereg.predict(X_test)

print(Ridreg_cv.best_params_)
print("Train score: {}, Test score: {}".format(Ridreg_cv.score(X_train,y_train),Ridreg_cv.score(X_test, y_test)))
print("MSE for Ridge Regression :",mean_squared_error(y_test, y_pred_rid))
print()

print(Lassreg_cv.best_params_)
print("Train score: {}, Test score: {}".format(Lassreg_cv.score(X_train, y_train),Lassreg_cv.score(X_test, y_test)))
print("MSE for Lasso Regression :",mean_squared_error(y_test, y_pred_lass),)
print()

print("Train score: {}, Test score: {}".format(Linereg.score(X_train, y_train),Linereg.score(X_test, y_test)))
print("MSE for Line Regression :",mean_squared_error(y_test,y_pred_line))

from sklearn.ensemble import AdaBoostRegressor
from sklearn.ensemble import BaggingRegressor

best_estimator = Lassreg_cv.best_estimator_

lasso_Ada = AdaBoostRegressor(base_estimator=best_estimator)
param_Ada = {'learning_rate': np.arange(0.01,1.1,0.01), 'loss': ['linear', 'square', 'exponential'], 'n_estimators': np.arange(5,55,5)}
lasso_Ada_cv = GridSearchCV(lasso_Ada, param_Ada, n_jobs = -1)

lasso_Ada_cv.fit(X_train, y_train)
y_pred_lasso_Ada = lasso_Ada_cv.predict(X_test)

print(lasso_Ada_cv.best_params_)
print("Train score : {}, Test score: {}".format(lasso_Ada_cv.score(X_train, y_train),lasso_Ada_cv.score(X_test, y_test)))
print("MSE for Lasso Regression + Adaboost :",mean_squared_error(y_test, y_pred_lasso_Ada))
print()

lasso_bag = BaggingRegressor(base_estimator=best_estimator)
param_bag = {'n_estimators': np.arange(5,55,5), 'max_features': np.arange(0.1,1.1,0.1), 'max_samples': np.arange(0.1,1.1,0.1)}
lasso_bag_cv = GridSearchCV(lasso_bag, param_bag, n_jobs = -1)

lasso_bag_cv.fit(X_train, y_train)
y_pred_lasso_bag = lasso_bag_cv.predict(X_test)

print(lasso_bag_cv.best_params_)
print("Train score : {}, Test score: {}".format(lasso_bag_cv.score(X_train, y_train),lasso_bag_cv.score(X_test, y_test)))
print("MSE for Lasso Regression + Bagging :",mean_squared_error(y_test, y_pred_lasso_bag))

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import RandomizedSearchCV

param = {'n_estimators': np.arange(100,2000,200),
        'criterion': ['mse','mae'], 
         'max_depth': np.arange(1,20,1), 
         'min_samples_split': [2,4,6,8], 
         'min_samples_leaf': np.arange(1,11,1), 
         'max_features': ['auto','sqrt','log2'],
}

rf_cv = RandomizedSearchCV(RandomForestRegressor(n_jobs = -1), param, n_jobs = -1)
rf_cv.fit(X_train, y_train)
y_pred_rf = rf_cv.predict(X_test)

print(rf_cv.best_params_)
print("Train score: {}, Test score: {}".format(rf_cv.score(X_train, y_train),rf_cv.score(X_test, y_test)))
print("MSE for Random Forest Regression :",mean_squared_error(y_test, y_pred_rf))
